### **Voice-Based Gender and Identity Detection**

📌 **Project Overview**

This project focuses on detecting gender and identifying speakers based on voice data using deep learning techniques. The dataset consists of audio recordings that are converted into spectrograms and numerical features for classification. Multiple deep learning architectures, including LSTM, Custom CNN, EfficientNet, and ResNet, were implemented to achieve optimal performance.

⚙️ **Methods Used**

LSTM (Long Short-Term Memory): Processes sequential audio features to capture temporal dependencies in speech signals.

Custom CNN (Convolutional Neural Network): Extracts spatial features from spectrogram images for classification.

EfficientNet & ResNet: Used as additional architectures for performance comparison.

🛠 **Technologies**

Python

Libraries: PyTorch, Librosa, NumPy, Pandas, Matplotlib

🚀 **Getting Started**

Installation & Usage

1. Clone the repository:
   git clone https://github.com/abdinlin22/DL_project_150200343_150220925.git
2. Navigate to the project folder:
   cd DL_project_150200343_150220925
3. Install required dependencies manually:
   pip install torch librosa numpy pandas matplotlib
4. Run the Jupyter Notebook:
   jupyter notebook Deep_Learning_Project_combined_plots_final.ipynb

🔮 **Future Enhancements**

Incorporate Wav2Vec for improved voice feature extraction.

Expand the dataset to include more diverse speaker profiles.

Deploy the model as a real-time voice classification API.

👥 **Contributors**

Aybike Battal - LSTM and Custom CNN Implementation

Nazrin Abdinli - EfficientNet and ResNet Implementation

📂 **Repository**

GitHub Link: https://github.com/abdinlin22/DL_project_150200343_150220925
